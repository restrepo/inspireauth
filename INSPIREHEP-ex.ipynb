{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5de1e640",
   "metadata": {},
   "source": [
    "# Construction of JSON object for experimental Authors, from INSPIRE-HEP\n",
    "<img src=\"https://raw.githubusercontent.com/restrepo/inspire/master/img/authors-ex.svg\" width=1000>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee1edb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from inspirehep import *\n",
    "class experimental_author(profile):\n",
    "    sleep = 0.4\n",
    "    #`ids → [{\"schema\": \"INSPIRE BAI\"}]` required for author_id\n",
    "    #`affiliations → [{...}] required for institution_id\n",
    "    schema_experimental_author={\"ids\": {'type':'list',\n",
    "                           'schema':{'type':'dict',\n",
    "                                     'schema':{'schema':{'type':'string'},\n",
    "                                               'value': {'type':'string'}\n",
    "                                              }\n",
    "                                    }\n",
    "                          }, \n",
    "            \"record\":{'type':'dict'}, \n",
    "            \"full_name\": {'type':'string'}, \n",
    "            \"affiliations\":{'type':'list',\n",
    "                           'schema':{'type':'dict','required':True}},\n",
    "            \"proyect_membership\":{'type':'list',\n",
    "                                    'schema':{'type':'dict',\n",
    "                                              'schema':{'record':{'type':'dict'},\n",
    "                                                        'name':{'type':'string'},\n",
    "                                                        'current':{'type':'boolean'}\n",
    "                                                       }\n",
    "                                             }\n",
    "                                },\n",
    "            \"name\":{'type':'dict',\n",
    "                    'schema':{'value':{'type':'string'},\n",
    "                              'preferred_name':{'type':'string'},\n",
    "                              }\n",
    "                    },\n",
    "            \"control_number\":{'type':'integer'},\n",
    "            \"arxiv_categories\":{'type':'list'}\n",
    "           }\n",
    "    sample_experimental_author={'project_membership': [{'name': 'CERN-LHC-CMS',\n",
    "                                    'record': {'$ref': 'https://inspirehep.net/api/experiments/1108642'},\n",
    "                                    'current': False,\n",
    "                                    'curated_relation': True}],\n",
    "                                'ids': [{'value': 'Y.Andreev.1', 'schema': 'INSPIRE BAI'}],\n",
    "                                'name': {'value': 'Andreev, Yuri',\n",
    "                                'preferred_name': 'Yuri Andreev'},\n",
    "                                'control_number': 1018372,\n",
    "                                'arxiv_categories': ['hep-ex']\n",
    "                                }\n",
    "    \n",
    "\n",
    "    def __init__(self,a,db=[]):\n",
    "        self.author=a\n",
    "        self.db=db\n",
    "        if a:\n",
    "            v=Validator(self.schema_experimental_author,allow_unknown=True)\n",
    "            if not v.validate(a):\n",
    "                raise Exception(f'''\n",
    "                    Input is not an INSPIRE-HEP author dictionary:\n",
    "                    {v.errors}\n",
    "                    See `self.sample_author`''')\n",
    "    def get_authors(self):\n",
    "        #TODO: Check previous analysis for more metadata\n",
    "        #use requests\n",
    "        # Not longer required\n",
    "\n",
    "        a=self.author\n",
    "\n",
    "\n",
    "        self.project_membership = a.get('project_membership')\n",
    "        control_number = a.get('control_number')\n",
    "        url = f\"https://inspirehep.net/api/authors/{control_number}\"\n",
    "        r=empty_json()\n",
    "\n",
    "        try:\n",
    "            r=requests.get(url,timeout=timeout)\n",
    "            time.sleep(self.sleep)\n",
    "        except:\n",
    "            r.status_code=-1\n",
    "        if r.status_code==200:\n",
    "            p=r.json().get('metadata')\n",
    "        else:\n",
    "            p={}\n",
    "        #We assume that the affilition is defined at least for\n",
    "        #one of the authors of the paper\n",
    "        #Authos without affiliations to get their institution are not considered\n",
    "        super(experimental_author, self).__init__(p)             \n",
    "        d=super(experimental_author, self).get_author() #→ self.profile\n",
    "        try:\n",
    "            self.full_name=p.get('name').get('value')\n",
    "        except:\n",
    "            self.full_name=''\n",
    "        self.profile_id=p.get('control_number')\n",
    "        try:\n",
    "            self.author_id=[i for i  in self.profile.get('ids') if i.get('schema')=='INSPIRE BAI'\n",
    "                        ][0].get('value')\n",
    "        except:\n",
    "            self.author_id=None \n",
    "\n",
    "        ll=[x for x in self.db if hasattr(x,'author_id') and hasattr(x,'institution_id')]\n",
    "        # TODO: Check if the author has multiple current positions\n",
    "        # for positions...\n",
    "        try:\n",
    "            current_position=self.profile.get('positions')[0]\n",
    "        except:\n",
    "            current_position={}\n",
    "        self.institution=current_position.get('institution')\n",
    "        try:\n",
    "            aff_url=current_position.get('record').get('$ref')\n",
    "        except:\n",
    "            aff_url=''\n",
    "        self.institution_id=aff_url.split('/')[-1]\n",
    "        # ==== country ====\n",
    "        self.country=None\n",
    "        if aff_url:\n",
    "            rr=empty_json()\n",
    "            try:\n",
    "                rr=requests.get(aff_url,timeout=timeout)\n",
    "                time.sleep(self.sleep)\n",
    "            except:\n",
    "                rr.status_code=-1\n",
    "            if rr.status_code==200:\n",
    "                try:\n",
    "                    self.country=rr.json().get('metadata').get('addresses')[0].get('country')\n",
    "                    # if self.country:\n",
    "                    #    self.cacheco[self.institution]=self.country\n",
    "                except:\n",
    "                    self.country=None\n",
    "        else:\n",
    "            self.country=None\n",
    "        # =================\n",
    "        filtered_db=[x for x in ll if x.author_id==self.author_id \n",
    "                         and x.institution_id==self.institution_id]\n",
    "        if filtered_db:\n",
    "            au=filtered_db[0] #must be unique!\n",
    "        else: #aff not in self.db → New affiliation\n",
    "            ai=copy.copy(self)#deepcopy(self)\n",
    "            self.db.append(ai)\n",
    "            del ai #be sure that ai will not be modified\n",
    "\n",
    "        return self.db\n",
    "    def to_json(self):\n",
    "        return [d.to_dict() for d in self.db]\n",
    "\n",
    "\n",
    "class experiment(experimental_author):\n",
    "    '''\n",
    "    paper['legacy_name']=ex.get('legacy_name')\n",
    "    paper['control_number']=ex.get('control_number')\n",
    "    paper['number_of_papers']=ex.get('number_of_papers')\n",
    "    paper['collaboration']=ex.get(\"collaboration\").get('value')\n",
    "    paper['literature_link']\n",
    "    '''\n",
    "    schema_experiment={'control_number':{'type':'integer','required':True},\n",
    "                       'number_of_papers':{'type':'integer'},\n",
    "                       'legacy_name':{'type':'string'},\n",
    "                       'collaboration':{'type':'dict',\n",
    "                                        'schema':{'value':{'type':'string'}}},\n",
    "                       'description':{'type':'string'},\n",
    "                       'accelerator':{'type':'dict',\n",
    "                                      'schema':{'value':{'type':'string'}}},\n",
    "                       'date_approved':{'type':'string'},\n",
    "                       'date_proposed':{'type':'string'},\n",
    "                       'date_started':{'type':'string'},\n",
    "                       'date_completed':{'type':'string'},\n",
    "                       'project_type':{'type':'list'},\n",
    "                       'inspire_classification':{'type':'list'}\n",
    "            }\n",
    "    def __init__(self,e,db=[],size=250):\n",
    "        self.sample_experiment = {'number_of_papers': 13049, #\n",
    "                                    'self': {'$ref': 'https://inspirehep.net/api/experiments/1108642'}, \n",
    "                                    'long_name': 'CMS: The Compact Muon Solenoid',\n",
    "                                    'accelerator': {'value': 'LHC'},\n",
    "                                    'description': 'The 27-km Large Hadron Collider (LHC) is the largest and most powerful particle accelerator ever built. It accelerates protons to nearly the velocity of light -- in clockwise and anti-clockwise directions -- and then collides them at four locations around its ring. At these points, the energy of the particle collisions gets transformed into mass, spraying particles in all directions. The Compact Muon Solenoid (or CMS) detector sits at one of these four collision points. It is a general-purpose detector; that is, it is designed to observe any new physics phenomena that the LHC might reveal. CMS acts as a giant, high-speed camera, taking 3D “photographs” of particle collisions from all directions up to 40 million times each second. Although most of the particles produced in the collisions are “unstable”, they transform rapidly into stable particles that can be detected by CMS. By identifying (nearly) all the stable particles produced in each collision, measuring their momenta and energies, and then piecing together the information of all these particles like putting together the pieces of a puzzle, the detector can recreate an “image” of the collision for further analysis.',\n",
    "                                    'legacy_name': 'CERN-LHC-CMS',\n",
    "                                    'date_approved': '1996-01-31', #\n",
    "                                    'date_proposed': '1992-10-01', #\n",
    "                                    'date_started': '2009-11-23', ##\n",
    "                                    'date_completed': '9999', #\n",
    "                                    'project_type': ['experiment'],\n",
    "                                    'collaboration': {'value': 'CMS'}, #\n",
    "                                    'control_number': 1108642, #\n",
    "                                    'inspire_classification': ['Collider Experiments|Hadrons|p p'] #\n",
    "                                    }\n",
    "        if e:\n",
    "            v=Validator(self.schema_experiment,allow_unknown=True)\n",
    "            if not v.validate(e):\n",
    "                raise Exception(f'''\n",
    "                    Input is not an INSPIRE-HEP experiment dictionary:\n",
    "                    {v.errors}\n",
    "                    See `self.sample_work`''')\n",
    "        \n",
    "        self.db = db\n",
    "        self.experiment = e\n",
    "        self.authors_size = size\n",
    "\n",
    "        \n",
    "    def get_authors(self):\n",
    "        '''\n",
    "        l: list of author objects\n",
    "        '''\n",
    "\n",
    "        l=self.experiment\n",
    "\n",
    "        #print(l.get('control_number'),end='\\r')\n",
    "        #TODO: Check previous analysis for more metadata\n",
    "        inspire_classification=l.get('inspire_classification')\n",
    "        if not inspire_classification:\n",
    "            inspire_classification = []\n",
    "        \n",
    "        control_number=l.get('control_number')\n",
    "\n",
    "        try:\n",
    "            year=int(l.get('date_started').split('-')[0])\n",
    "        except:\n",
    "            year=0\n",
    "        if not year:\n",
    "            year=9999\n",
    "        #'inst_id':aff_id\n",
    "        paper={}\n",
    "        paper['legacy_name'] = l.get('legacy_name')\n",
    "        paper['control_number'] = control_number\n",
    "        paper['number_of_papers']=l.get('number_of_papers')\n",
    "        try:\n",
    "            paper['collaboration']=l.get(\"collaboration\").get('value')\n",
    "        except:\n",
    "            paper['collaboration']=None\n",
    "        paper['literature_link']=f\"https://inspirehep.net/api/literature?size=25&page=1&q=collaboration:{paper.get('collaboration')}\"\n",
    "        paper['year']=year\n",
    "        paper['inspire_classification']=inspire_classification\n",
    "        paper['dates'] = {'approved':l.get('date_approved'),\n",
    "                          'proposed':l.get('date_proposed'),\n",
    "                          'started':l.get('date_started'), \n",
    "                          'completed':l.get('date_completed')}\n",
    "        paper['long_name']=l.get('long_name')\n",
    "        paper['description']=l.get('description')\n",
    "        try:\n",
    "            paper['accelerator']=l.get('accelerator').get('value')\n",
    "        except:\n",
    "            paper['accelerator']=None\n",
    "        paper['project_type']=l.get('project_type')      \n",
    "\n",
    "\n",
    "        #In update\n",
    "        #'primary_arxiv_category':primary_arxiv_category\n",
    "        #super(work, self).__init__(w.get('authors')[0])\n",
    "\n",
    "        r=empty_json()\n",
    "        # TODO: load all pages\n",
    "        NEXT=True\n",
    "        i=0        \n",
    "        while NEXT:\n",
    "            if i==0:\n",
    "                url=f'https://inspirehep.net/api/authors?q=project_membership.record.%24ref%3A{control_number}&page=1&size={self.authors_size}'\n",
    "            try:\n",
    "                r=requests.get(url,timeout=timeout)\n",
    "                time.sleep(self.sleep)\n",
    "            except:\n",
    "                r.status_code=-1\n",
    "            if r.status_code==200:\n",
    "                aus=r.json().get('hits').get('hits')\n",
    "            else:\n",
    "                aus=[]\n",
    "            if i==0 and len(aus)==250:\n",
    "                try:\n",
    "                    paper['description']=paper['description'][:20]+'...'\n",
    "                except:\n",
    "                    paper['description']=''\n",
    "            #print(i,url,len(aus))\n",
    "\n",
    "            for a in aus: #same self.author_id but several institute_ids for several affiliations\n",
    "                super(experiment, self).__init__(a.get('metadata'),self.db)\n",
    "                super(experiment, self).get_authors() #add and replace self attributes → author*..., institution*..\n",
    "                paper['author_id']=self.author_id\n",
    "                paper['profile_id']=self.profile_id\n",
    "                #Each d object keeps its RAM memory space independent of reasignation list from db to adb\n",
    "                adb=[d for d in self.db if d.author_id==self.author_id]\n",
    "\n",
    "                papers = []\n",
    "                for d in adb:\n",
    "                    if hasattr(d,'papers'):\n",
    "                        papers=d.papers\n",
    "                        break #found papers for self.author_id\n",
    "                for d in adb:\n",
    "                    d.papers=papers #reatach papers if already have\n",
    "                    if paper not in d.papers:\n",
    "                        #detach from RAM!\n",
    "                        cppaper=copy.copy(paper)\n",
    "                        d.papers.append(cppaper)\n",
    "                        del cppaper\n",
    "            \n",
    "            links=r.json().get('links')\n",
    "            try:\n",
    "                total=r.json().get('hits').get('total')\n",
    "            except:\n",
    "                total=0\n",
    "            try:\n",
    "                if links.get('next'):\n",
    "                    url=links.get('next')\n",
    "                else:\n",
    "                    NEXT=False\n",
    "            except:\n",
    "                NEXT=False\n",
    "            #EMERGENCY EXIT: We assume here that r.json().get('total') exists\n",
    "            if i > total//self.authors_size+1:\n",
    "                NEXT=False\n",
    "            i+=1            \n",
    "\n",
    "        return self.db\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7be1315",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#DEFINE TEST\n",
    "sample_experimental_author={'project_membership': [{'name': 'CERN-LHC-CMS',\n",
    "                                    'record': {'$ref': 'https://inspirehep.net/api/experiments/1108642'},\n",
    "                                    'current': False,\n",
    "                                    'curated_relation': True}],\n",
    "                                'ids': [{'value': 'Y.Andreev.1', 'schema': 'INSPIRE BAI'}],\n",
    "                                'name': {'value': 'Andreev, Yuri',\n",
    "                                'preferred_name': 'Yuri Andreev'},\n",
    "                                'control_number': 1018372,\n",
    "                                'arxiv_categories': ['hep-ex']\n",
    "                                }\n",
    "a=experimental_author(sample_experimental_author)\n",
    "db=a.get_authors()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "737386c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 https://inspirehep.net/api/authors?q=project_membership.record.%24ref%3A1108642&page=1&size=5\n",
      "1 https://inspirehep.net/api/authors/?q=project_membership.record.%24ref%3A1108642&size=5&page=2\n"
     ]
    }
   ],
   "source": [
    "#DEFINE TEST\n",
    "sample_experiment = {'number_of_papers': 13049, #\n",
    "                                    'self': {'$ref': 'https://inspirehep.net/api/experiments/1108642'}, \n",
    "                                    'long_name': 'CMS: The Compact Muon Solenoid',\n",
    "                                    'accelerator': {'value': 'LHC'},\n",
    "                                    'description': 'The 27-km Large Hadron Collider (LHC) is the largest and most powerful particle accelerator ever built. It accelerates protons to nearly the velocity of light -- in clockwise and anti-clockwise directions -- and then collides them at four locations around its ring. At these points, the energy of the particle collisions gets transformed into mass, spraying particles in all directions. The Compact Muon Solenoid (or CMS) detector sits at one of these four collision points. It is a general-purpose detector; that is, it is designed to observe any new physics phenomena that the LHC might reveal. CMS acts as a giant, high-speed camera, taking 3D “photographs” of particle collisions from all directions up to 40 million times each second. Although most of the particles produced in the collisions are “unstable”, they transform rapidly into stable particles that can be detected by CMS. By identifying (nearly) all the stable particles produced in each collision, measuring their momenta and energies, and then piecing together the information of all these particles like putting together the pieces of a puzzle, the detector can recreate an “image” of the collision for further analysis.',\n",
    "                                    'legacy_name': 'CERN-LHC-CMS',\n",
    "                                    'date_approved': '1996-01-31', #\n",
    "                                    'date_proposed': '1992-10-01', #\n",
    "                                    'date_started': '2009-11-23', ##\n",
    "                                    'date_completed': '9999', #\n",
    "                                    'project_type': ['experiment'],\n",
    "                                    'collaboration': {'value': 'CMS'}, #\n",
    "                                    'control_number': 1108642, #\n",
    "                                    'inspire_classification': ['Collider Experiments|Hadrons|p p'] #\n",
    "                                    }\n",
    "e=experiment(sample_experiment,size=5)\n",
    "db=e.get_authors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ad0dc976",
   "metadata": {},
   "outputs": [],
   "source": [
    "test=[{'updated': '2022-01-28T11:24:41.532294+00:00',\n",
    "  'created': '2012-04-13T00:00:00+00:00',\n",
    "  'metadata': {'number_of_papers': 954,\n",
    "   'facet_inspire_classification': ['Collider|Heavy Flavor Factory',\n",
    "    'Collider|e+ e-'],\n",
    "   'normalized_name_variants': ['CLEO', 'CLEO'],\n",
    "   'core': True,\n",
    "   'self': {'$ref': 'https://inspirehep.net/api/experiments/1109984'},\n",
    "   'urls': [{'value': 'http://w4.lns.cornell.edu/public/CLEO/'}],\n",
    "   '$schema': 'https://inspirehep.net/schemas/records/experiments.json',\n",
    "   'long_name': 'The {CLEO} Experiment at {CESR}',\n",
    "   'accelerator': {'value': 'CESR'},\n",
    "   'description': 'Since 1979 the collaboration has conducted studies of b, c, tau and gamma-gamma physics in e+ e- interactions near 10 GeV. Current topics include determination of the CKM parameters and the Standard Model tests in decays of heavy flavors, as well as QCD tests in a variety of processes. Successive detector upgrades have kept pace with luminosity improvements to the Cornell Electron Storage Ring (CESR), which has delivered over 6/fb of integrated luminosity to date. The CLEO-II detector (proposed 1983, approved 1984, operational since 1989) consists of drift chambers for tracking charged particles and measuring dE / dx, time-of-flight counters, a 7800-element CsI electromagnetic calorimeter, a 1.5-tesla superconducting solenoid, iron for flux return and muon identification, and muon chambers. A three-layer silicon vertex detector was added in the Fall of 1995. Taking data (July 96). A major upgrade, the CLEO-III detector, was proposed and approved in 1994, and the installation is planned for 1998.',\n",
    "   'legacy_name': 'CESR-CLEO',\n",
    "   'date_started': '1979-10',\n",
    "   'institutions': [{'value': 'Cornell U.',\n",
    "     'record': {'$ref': 'https://inspirehep.net/api/institutions/911819'},\n",
    "     'curated_relation': True}],\n",
    "   'project_type': ['experiment'],\n",
    "   'collaboration': {'value': 'CLEO', 'curated_relation': False},\n",
    "   'date_approved': '1977',\n",
    "   'date_proposed': '1975',\n",
    "   'name_variants': ['CLEO'],\n",
    "   'control_number': 1109984,\n",
    "   'date_completed': '9999',\n",
    "   'legacy_version': '20200123205452.0',\n",
    "   'legacy_creation_date': '2012-04-13',\n",
    "   'inspire_classification': ['Collider Experiments|Heavy Flavor Factory',\n",
    "    'Collider Experiments|e+ e-'],\n",
    "   'external_system_identifiers': [{'value': 'EXPERIMENT-6963',\n",
    "     'schema': 'SPIRES'}]},\n",
    "  'links': {'json': 'https://inspirehep.net/api/experiments/1109984?format=json'},\n",
    "  'id': '1109984'}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4425e93-dd3f-4728-b8fc-6f17d7dd976d",
   "metadata": {},
   "source": [
    "## Run for all the experiment entries in inspirehep.net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f724f0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbj_all = []\n",
    "dbj_la = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc4e8cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "f=open('inspire-ex.json','r')\n",
    "dbj_all=json.load(f)\n",
    "f.close()\n",
    "f=open('inspire_LA-ex.json','r')\n",
    "dbj_la=json.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043524b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_json(dbj,dbj_all):\n",
    "    for d in dbj:\n",
    "        if d.get('profile_id') in [d.get('profile_id') for d in dbj_all]:\n",
    "            for dd in dbj_all:\n",
    "                if d.get('profile_id')==dd.get('profile_id') and d not in dbj_all:\n",
    "                    if len(d.get('papers'))>0 and d.get('papers')[0] not in dd.get('papers'):\n",
    "                        dd.get('papers').append(d.get('papers')[0])\n",
    "        else:\n",
    "            if d not in dbj_all:\n",
    "                dbj_all.append(d)\n",
    "    return dbj_all\n",
    "\n",
    "LA_countries=['Brazil', 'Mexico', 'Argentina','Chile', 'Colombia','Bolivia','Cuba', #5\n",
    "              'Costa Rica', 'Ecuador', 'El Salvador', 'Guatemala', 'Honduras', #10\n",
    "               'Nicaragua', 'Panama', 'Paraguay', 'Peru', #15\n",
    "              'Dominican Republic','Uruguay','Venezuela']\n",
    "q=''#'FNAL-E-0690'\n",
    "size=250\n",
    "sleep=0.4\n",
    "r = empty_json()\n",
    "# TODO: load all pages\n",
    "NEXT=True\n",
    "i=0        \n",
    "while NEXT:\n",
    "    if i==0:\n",
    "        url=f'https://inspirehep.net/api/experiments?size={size}'\n",
    "        if q:\n",
    "            url=f'{url}&q={q}'\n",
    "    try:\n",
    "        r=requests.get(url,timeout=timeout)\n",
    "        time.sleep(sleep)\n",
    "    except:\n",
    "        r.status_code=-1\n",
    "    print(i,url,r.status_code)\n",
    "\n",
    "    if r.status_code==200:\n",
    "        exps=r.json().get('hits').get('hits')\n",
    "    else:\n",
    "        exps=[]\n",
    "    #exps=[e for e in exps if e.get('metadata').get('control_number')==1109984]\n",
    "    for e in exps: #same self.author_id but several institute_ids for several affiliations\n",
    "        if e.get('metadata').get('control_number') in set([x for sublist in \n",
    "                  [[dd.get('control_number') for dd in d.get('papers')] \n",
    "                  for d in dbj_all] for x in sublist]):\n",
    "                  continue\n",
    "        expr=experiment(e.get('metadata'),db=[],size=250)\n",
    "        db_ex=expr.get_authors()\n",
    "        dbj=expr.to_json()\n",
    "        dbj_all=update_json(dbj,dbj_all)\n",
    "        if set(LA_countries).intersection(set([d.country for d in db_ex])):\n",
    "            dbj_la=update_json(dbj,dbj_la)\n",
    "        print(str(i).zfill(4),'→',e.get('metadata').get('control_number'),\n",
    "                      str(len(db_ex)).zfill(4),str(len(dbj)).zfill(4),\n",
    "                      str(len(dbj_all)).zfill(5),str(len(dbj_la)).zfill(5),end='\\r')\n",
    "\n",
    "    f=open('inspire-ex.json','w')\n",
    "    json.dump(dbj_all,f)\n",
    "    f.close()\n",
    "    f=open('inspire_LA-ex.json','w')\n",
    "    json.dump(dbj_la,f)\n",
    "    f.close()\n",
    "\n",
    "    links=r.json().get('links')\n",
    "    total=r.json().get('hits').get('total')                \n",
    "    if links.get('next'):\n",
    "        url=links.get('next')\n",
    "    else:\n",
    "        NEXT=False\n",
    "    #EMERGENCY EXIT: We assume here that r.json().get('total') exists\n",
    "    #if i==0:\n",
    "    #    NEXT=False\n",
    "    if i > total//size+1:\n",
    "        NEXT=False\n",
    "    i+=1\n",
    "    #Fix duplicated authors\n",
    "    f=open('inspire-ex.json','w')\n",
    "    json.dump(dbj_all,f)\n",
    "    f.close()\n",
    "    f=open('inspire_LA-ex.json','w')\n",
    "    json.dump(dbj_la,f)\n",
    "    f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
